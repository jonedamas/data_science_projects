{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import yfinance as yf\n",
    "import seaborn as sns\n",
    "\n",
    "from arch import arch_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from arch.__future__ import reindexing\n",
    "\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "def add_log_returns(close):\n",
    "    log_returns = np.log(close/close.shift())\n",
    "    return log_returns\n",
    "\n",
    "# def add_GARCH(close, lr, test_size = 1250):\n",
    "#     rolling_predictions = list()\n",
    "\n",
    "#     for i in range(test_size):\n",
    "#         train = lr.dropna()[:-(test_size-i)]\n",
    "#         model = arch_model(100 * train, p=1, q=1, mean='constant', vol='GARCH')\n",
    "#         model_fit = model.fit(disp='off')\n",
    "#         pred = model_fit.forecast(horizon=1, reindex=True)\n",
    "#         rolling_predictions.append(np.sqrt(pred.variance.values[-1,:][0]))\n",
    "\n",
    "#     GARCH = pd.Series(rolling_predictions, index=lr.index[-test_size:]) / 100\n",
    "\n",
    "#     return GARCH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility spillover analysis\n",
    "\n",
    "- Variance Decomposition: Variance decomposition techniques, such as the Cholesky decomposition, can help quantify the contribution of each market to the overall volatility spillover. By decomposing the total volatility into individual components, you can assess the extent to which shocks in one market affect the volatility of other markets.\n",
    "\n",
    "- Granger Causality: Granger causality tests can determine if past values of one market's volatility help predict the future volatility of another market. If there is significant causality between two markets, it suggests the presence of volatility spillover. Various time series econometric methods, such as Vector Autoregression (VAR) or Multivariate GARCH models, can be used to perform Granger causality tests.\n",
    "\n",
    "- Spillover Index: Spillover indices, such as the Diebold and Yilmaz spillover index, measure the interconnectedness or transmission of volatility between different markets. These indices provide a quantitative measure of the volatility spillover effects across markets, indicating the strength and direction of transmission.\n",
    "\n",
    "- Co-integration Analysis: Co-integration analysis examines the long-term relationship between multiple markets. If there is a co-integrating relationship among markets, it suggests a long-term equilibrium and the possibility of volatility spillover.\n",
    "\n",
    "- Correlation and Cross-Correlation Analysis: Correlation analysis can identify the degree of linear relationship between market volatilities. High correlation indicates a potential for volatility spillover. Cross-correlation analysis examines the lagged correlations between market volatilities to determine if there is a lead-lag relationship or spillover effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BZ=F</th>\n",
       "      <th>GC=F</th>\n",
       "      <th>OSEBX.OL</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>lr_BZ=F</th>\n",
       "      <th>lr_GC=F</th>\n",
       "      <th>lr_OSEBX.OL</th>\n",
       "      <th>lr_^GSPC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-03</th>\n",
       "      <td>77.760002</td>\n",
       "      <td>1251.599976</td>\n",
       "      <td>877.979980</td>\n",
       "      <td>2713.219971</td>\n",
       "      <td>-0.020997</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>-0.004960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04</th>\n",
       "      <td>77.760002</td>\n",
       "      <td>1251.599976</td>\n",
       "      <td>879.429993</td>\n",
       "      <td>2713.219971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05</th>\n",
       "      <td>77.389999</td>\n",
       "      <td>1257.300049</td>\n",
       "      <td>883.390015</td>\n",
       "      <td>2736.610107</td>\n",
       "      <td>-0.004770</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.008584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-06</th>\n",
       "      <td>77.110001</td>\n",
       "      <td>1254.300049</td>\n",
       "      <td>877.340027</td>\n",
       "      <td>2759.820068</td>\n",
       "      <td>-0.003625</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>0.008446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-09</th>\n",
       "      <td>78.070000</td>\n",
       "      <td>1258.099976</td>\n",
       "      <td>888.659973</td>\n",
       "      <td>2784.169922</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.008784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>74.180000</td>\n",
       "      <td>1923.699951</td>\n",
       "      <td>1195.699951</td>\n",
       "      <td>4328.819824</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>-0.004497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>72.260002</td>\n",
       "      <td>1914.000000</td>\n",
       "      <td>1186.150024</td>\n",
       "      <td>4378.410156</td>\n",
       "      <td>-0.026224</td>\n",
       "      <td>-0.005055</td>\n",
       "      <td>-0.008019</td>\n",
       "      <td>0.011391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>74.029999</td>\n",
       "      <td>1912.300049</td>\n",
       "      <td>1198.670044</td>\n",
       "      <td>4376.859863</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>-0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29</th>\n",
       "      <td>74.339996</td>\n",
       "      <td>1909.199951</td>\n",
       "      <td>1210.130005</td>\n",
       "      <td>4396.439941</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>-0.001622</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.004464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>74.900002</td>\n",
       "      <td>1927.800049</td>\n",
       "      <td>1214.119995</td>\n",
       "      <td>4450.379883</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>0.009695</td>\n",
       "      <td>0.003292</td>\n",
       "      <td>0.012194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1287 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BZ=F         GC=F     OSEBX.OL        ^GSPC   lr_BZ=F  \\\n",
       "Date                                                                     \n",
       "2018-07-03  77.760002  1251.599976   877.979980  2713.219971 -0.020997   \n",
       "2018-07-04  77.760002  1251.599976   879.429993  2713.219971  0.000000   \n",
       "2018-07-05  77.389999  1257.300049   883.390015  2736.610107 -0.004770   \n",
       "2018-07-06  77.110001  1254.300049   877.340027  2759.820068 -0.003625   \n",
       "2018-07-09  78.070000  1258.099976   888.659973  2784.169922  0.012373   \n",
       "...               ...          ...          ...          ...       ...   \n",
       "2023-06-26  74.180000  1923.699951  1195.699951  4328.819824  0.004459   \n",
       "2023-06-27  72.260002  1914.000000  1186.150024  4378.410156 -0.026224   \n",
       "2023-06-28  74.029999  1912.300049  1198.670044  4376.859863  0.024200   \n",
       "2023-06-29  74.339996  1909.199951  1210.130005  4396.439941  0.004179   \n",
       "2023-06-30  74.900002  1927.800049  1214.119995  4450.379883  0.007505   \n",
       "\n",
       "             lr_GC=F  lr_OSEBX.OL  lr_^GSPC  \n",
       "Date                                         \n",
       "2018-07-03  0.009473     0.005998 -0.004960  \n",
       "2018-07-04  0.000000     0.001650  0.000000  \n",
       "2018-07-05  0.004544     0.004493  0.008584  \n",
       "2018-07-06 -0.002389    -0.006872  0.008446  \n",
       "2018-07-09  0.003025     0.012820  0.008784  \n",
       "...              ...          ...       ...  \n",
       "2023-06-26  0.002394     0.001431 -0.004497  \n",
       "2023-06-27 -0.005055    -0.008019  0.011391  \n",
       "2023-06-28 -0.000889     0.010500 -0.000354  \n",
       "2023-06-29 -0.001622     0.009515  0.004464  \n",
       "2023-06-30  0.009695     0.003292  0.012194  \n",
       "\n",
       "[1287 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tickers = ['BZ=F', 'GC=F', 'OSEBX.OL', '^GSPC']\n",
    "\n",
    "log_returns = [ f'lr_{tic}' for tic in tickers]\n",
    "# Import stock data\n",
    "data = pd.DataFrame(yf.download(tickers, period='5Y', interval='1d', progress=False, ignore_tz=True)['Adj Close'])\n",
    "\n",
    "# Forward fill\n",
    "data = data.ffill()\n",
    "\n",
    "# Add log_returns and GARCH\n",
    "for tic in tickers:\n",
    "    data[f'lr_{tic}'] = add_log_returns(data[tic])\n",
    "    # data[f'GARCH_{tic}'] = add_GARCH(data[tic], data[f'lr_{tic}'])\n",
    "\n",
    "display(data.dropna())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jone\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  Summary of Regression Results   \n",
       "==================================\n",
       "Model:                         VAR\n",
       "Method:                        OLS\n",
       "Date:           Wed, 05, Jul, 2023\n",
       "Time:                     00:21:26\n",
       "--------------------------------------------------------------------\n",
       "No. of Equations:         4.00000    BIC:                   -34.2007\n",
       "Nobs:                     966.000    HQIC:                  -34.2132\n",
       "Log likelihood:           11049.9    FPE:                1.37427e-15\n",
       "AIC:                     -34.2209    Det(Omega_mle):     1.36860e-15\n",
       "--------------------------------------------------------------------\n",
       "Results for equation lr_BZ=F\n",
       "========================================================================\n",
       "           coefficient       std. error           t-stat            prob\n",
       "------------------------------------------------------------------------\n",
       "const         0.000315         0.000986            0.320           0.749\n",
       "========================================================================\n",
       "\n",
       "Results for equation lr_GC=F\n",
       "========================================================================\n",
       "           coefficient       std. error           t-stat            prob\n",
       "------------------------------------------------------------------------\n",
       "const         0.000452         0.000318            1.422           0.155\n",
       "========================================================================\n",
       "\n",
       "Results for equation lr_OSEBX.OL\n",
       "========================================================================\n",
       "           coefficient       std. error           t-stat            prob\n",
       "------------------------------------------------------------------------\n",
       "const         0.000388         0.000377            1.030           0.303\n",
       "========================================================================\n",
       "\n",
       "Results for equation lr_^GSPC\n",
       "========================================================================\n",
       "           coefficient       std. error           t-stat            prob\n",
       "------------------------------------------------------------------------\n",
       "const         0.000529         0.000440            1.204           0.229\n",
       "========================================================================\n",
       "\n",
       "Correlation matrix of residuals\n",
       "                lr_BZ=F   lr_GC=F  lr_OSEBX.OL  lr_^GSPC\n",
       "lr_BZ=F        1.000000  0.088517     0.407037  0.323811\n",
       "lr_GC=F        0.088517  1.000000    -0.003873  0.053501\n",
       "lr_OSEBX.OL    0.407037 -0.003873     1.000000  0.528027\n",
       "lr_^GSPC       0.323811  0.053501     0.528027  1.000000\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_45552\\2095485062.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mforecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlag_order\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Convert the forecasted values to a DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jone\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py\u001b[0m in \u001b[0;36mforecast\u001b[1;34m(self, y, steps, exog_future)\u001b[0m\n\u001b[0;32m   1161\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m             \u001b[0mexog_future\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrend_coefs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog_future\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m     \u001b[1;31m# TODO: use `mse` module-level function?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jone\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py\u001b[0m in \u001b[0;36mforecast\u001b[1;34m(y, coefs, trend_coefs, steps, exog)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m    230\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         raise ValueError(\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "\n",
    "var_data = data[log_returns].dropna()\n",
    "\n",
    "test_prop = 0.25\n",
    "test_size = (int(len(var_data)*test_prop))\n",
    "\n",
    "cointegration_results = coint_johansen(var_data, det_order=0, k_ar_diff=1)\n",
    "eigenvalues = cointegration_results.eig\n",
    "\n",
    "optimal_lags = np.argmax(eigenvalues)\n",
    "\n",
    "\n",
    "train = var_data.iloc[:-test_size]\n",
    "test = var_data.iloc[-test_size:]\n",
    "\n",
    "model = VAR(train)\n",
    "results = model.fit(optimal_lags)\n",
    "\n",
    "lag_order = results.k_ar\n",
    "\n",
    "display(results.summary())\n",
    "\n",
    "forecast = results.forecast(train.values[-lag_order:], steps=len(test))\n",
    "\n",
    "# Convert the forecasted values to a DataFrame\n",
    "forecast_df = pd.DataFrame(forecast, index=test.index, columns=test.columns)\n",
    "\n",
    "# Evaluate the forecast accuracy\n",
    "mse = ((forecast_df - test) ** 2).mean()\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
